# Multi-LLM Collaborative Debate System

A sophisticated problem-solving system where multiple Large Language Models (LLMs) collaborate through structured debate to produce high-quality answers. The system leverages diverse AI perspectives and adversarial review to combat hallucination and improve accuracy.

## ğŸ¯ Overview

This system implements a multi-stage debate workflow:

1. **Role Assignment (Stage 0/0.5)**: Four LLMs self-assess their capabilities and are algorithmically assigned roles
2. **Independent Solutions (Stage 1)**: Three Solvers generate solutions independently with detailed reasoning
3. **Peer Review (Stage 2)**: Each Solver critically evaluates the other two solutions
4. **Refinement (Stage 3)**: Solvers refine their solutions based on peer feedback
5. **Final Judgment (Stage 4)**: A Judge LLM evaluates all refined solutions and selects the best answer

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Problem Input                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 0: Role Self-Assessment                       â”‚
â”‚         GPT â”‚ Claude â”‚ Gemini â”‚ Grok                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 0.5: Algorithmic Role Assignment              â”‚
â”‚         â†’ 3 Solvers + 1 Judge                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 1: Independent Solutions                      â”‚
â”‚         Solver 1 â”‚ Solver 2 â”‚ Solver 3                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 2: Peer Review                                â”‚
â”‚         Each solver reviews 2 peer solutions                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 3: Refinement                                 â”‚
â”‚         Address critiques â†’ Improved solutions                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 4: Final Judgment                             â”‚
â”‚         Judge selects best answer                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Final Answer                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Final/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py              # API keys and model settings
â”œâ”€â”€ data/
â”‚   â””â”€â”€ problems.json          # 25-problem dataset
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_clients/           # LLM API client implementations
â”‚   â”‚   â”œâ”€â”€ base_client.py     # Abstract base class
â”‚   â”‚   â”œâ”€â”€ openai_client.py   # GPT
â”‚   â”‚   â”œâ”€â”€ anthropic_client.py # Claude
â”‚   â”‚   â”œâ”€â”€ google_client.py   # Gemini
â”‚   â”‚   â””â”€â”€ xai_client.py      # Grok
â”‚   â”œâ”€â”€ stages/                # Debate stage implementations
â”‚   â”‚   â”œâ”€â”€ role_assignment.py # Stage 0 & 0.5
â”‚   â”‚   â”œâ”€â”€ solver.py          # Stage 1
â”‚   â”‚   â”œâ”€â”€ peer_review.py     # Stage 2
â”‚   â”‚   â”œâ”€â”€ refinement.py      # Stage 3
â”‚   â”‚   â””â”€â”€ judge.py           # Stage 4
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py         # Evaluation metrics
â”‚   â”‚   â””â”€â”€ baselines.py       # Baseline comparisons
â”‚   â””â”€â”€ orchestrator.py        # Main workflow coordinator
â”œâ”€â”€ visualization/
â”‚   â””â”€â”€ plots.py               # Matplotlib/Seaborn visualizations
â”œâ”€â”€ results/                   # Output directory
â”œâ”€â”€ main.py                    # Entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd Final
```

2. **Create a virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure API keys**

Create a `.env` file in the project root:
```env
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GOOGLE_API_KEY=your_google_api_key
XAI_API_KEY=your_xai_api_key
```

## ğŸ“Š Usage

### Run Full Pipeline
```bash
python main.py --full
```
This runs the complete pipeline: debate system, baselines, evaluation, and visualization.

### Run Individual Components
```bash
# Run debate system only
python main.py --run-debate

# Run baseline comparisons
python main.py --run-baselines

# Evaluate existing results
python main.py --evaluate

# Generate plots from existing results
python main.py --generate-plots

# Check API key configuration
python main.py --check-keys
```

### Additional Options
```bash
# Limit number of problems (useful for testing)
python main.py --full --limit 5

# Use custom problems file
python main.py --full --problems-file path/to/problems.json
```

## ğŸ“ˆ Evaluation Metrics

The system tracks the following metrics:

- **Overall Accuracy**: Percentage of problems solved correctly
- **Improvement Rate**: Problems where refinement improved initial answers
- **Consensus Rate**: Problems where all 3 Solvers agreed
- **Judge Accuracy**: Correct selections when Solvers disagreed
- **Per-Category Accuracy**: Breakdown by problem type
- **Model Performance**: Individual model statistics by role

### Baseline Comparisons

- **Single-LLM Baseline**: Each model asked once independently
- **Simple Voting Baseline**: 3 models vote, majority wins
- **Full Debate System**: Complete multi-stage workflow

## ğŸ“‹ Problem Dataset

The dataset includes 25 challenging problems across 4 categories:

| Category | Count | Description |
|----------|-------|-------------|
| Mathematical/Logical | 7 | Combinatorics, probability, number theory |
| Physics/Scientific | 6 | Multi-step physics, counterintuitive scenarios |
| Logic Puzzles | 6 | Knights/knaves, constraint satisfaction |
| Game Theory | 6 | Auctions, Nash equilibria, backward induction |

## ğŸ“Š Generated Visualizations

The system generates the following plots in `results/plots/`:

1. **accuracy_by_category.png**: Bar chart of accuracy by problem category
2. **system_vs_baselines.png**: Comparison chart vs. baseline methods
3. **model_performance_heatmap.png**: Heatmap of model performance by role
4. **improvement_through_stages.png**: Line chart showing accuracy improvement
5. **judge_confusion_matrix.png**: Judge decision analysis
6. **consensus_analysis.png**: Consensus vs. disagreement outcomes

## ğŸ”§ Configuration

### Model Settings (config/config.py)

```python
# Adjust model parameters
OPENAI_CONFIG = ModelConfig(
    name="GPT",
    model_id="GPT-turbo-preview",
    max_tokens=4096,
    temperature=0.7
)
```

### System Settings

```python
SYSTEM_CONFIG = SystemConfig(
    api_timeout=120,      # API call timeout
    max_retries=3,        # Retry attempts
    retry_delay=1.0,      # Delay between retries
    results_dir="results" # Output directory
)
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“ License

This project is for educational purposes as part of a course final project.

## ğŸ‘¥ Authors

Multi-LLM Debate Team

## ğŸ™ Acknowledgments

- OpenAI for GPT
- Anthropic for Claude
- Google for Gemini
- xAI for Grok
